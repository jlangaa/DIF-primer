---
title: "DIF Primer"
author: "Josh Langfus"
date: "`r Sys.Date()`"
output: pdf_document
---

# Setup

Make sure the packages below are installed.

```{r setup, include=FALSE}
library(mirt)
library(difR)
library(tidyverse)

knitr::opts_chunk$set(echo = TRUE)
```

Read in the data

```{r read data}
data_path <- "../data/test_data.csv"

dat <- read.csv(data_path)
```

Check that the data were read in successfully

```{r}
head(dat)
```

You should see a `sex` column followed by 36 other columns that represent the item-level data.

# About these data

The data represent responses from 411 parents about their children on three different scales. They also reported the child's sex assigned at birth. The three scales are: the GBI10d (a depression measure), the GBI10m (measure of mania symptoms), and the RAGA (a measure of reactive aggression).

Except for the `sex` column, the column names tell you the name of the measure and the item number. So for example, the column titled `raga_08` contains item 8 from the RAGA; `gbi10m_03` has item 3 from the GBI10m. The two GBI scales have 10 items each; the RAGA has 16 items.

These scales have known factor structures. The two GBI scales are unidimensional -- i.e., all ten items on each scale measure one "thing." For the 10m, it's mania symptoms and for the 10d it's depression symptoms. The RAGA has a more complex factor structure. Although all the items measure reactive aggression to some extent, the first 8 items (`raga_01` to `raga_08`) measure "temper loss" and the latter 8 (`raga_09` to `raga_16`) measure "aggressive behavior." The details here aren't important for the current example; all you need to know is that there are two correlated factors.

# A bit about DIF

The (very) basic goal of DIF is to find out if some of the items on your measure behave differently based on some grouping variable. Note that "behave differently" is doing a lot of work here, but I'm going to move past the details for the purposes of showing you how DIF works. To really understand what's "behaving differently," though, it's important to understand how IRT works.

One challenge of doing DIF -- maybe the central challenge -- is that to know if *some* of the items are behaving differently, we need to have another set of items on the scale that we think are *not* behaving differently to provide a basis of comparison. These are called "anchor items." How do you know which items aren't DIF-y if the whole point is that we're trying to figure that out? It's a great question -- one that has plagued the field since it's inception.

There are two ways of looking at DIF. One way is to use a procedure called a "Mantel-Haenszel Test", which helps establish whether there is potential DIF on any of the items. The second way is to fit an IRT model and use invariance testing. The examples below will show both.

The MH test matches respondents in both groups based on some other variable (by default, the total score on the test) and looks to see if there are significant differences in item performance in those strata. There are a lot of technical details and caveats which, again, I'll ignore -- but take a look at the Teresi et al. reading if you're curious.

# Doing the DIF - MH Test

For this example, we're going to look at differential item function across the `sex` variable. We'll do this in two stages. We'll start with examining just the GBI10d items.

For simplicity, let's split the data into three separate data frames, one for each measure, and each one also containing the `sex` column. This will make it easier to use the functions later on. Note that for the Sex variable, 0 = female and 1 = male (which were the only sexes reported in this sample). There was one person who did not respond to this question, and they have an `NA` value.

```{r data wrangle}
gbi10d <- dat %>%
  select(sex, starts_with("gbi10d"))

gbi10m <- dat %>%
  select(sex, starts_with("gbi10d"))

raga <- dat %>%
  select(sex, starts_with("raga"))
```

## GBI 10-D MH test

In the function call below, we use `difMH()` from the `difR` package to run the MH test. As arguments, we give it the data frame with our items (and the grouping variable). Then we tell it which column contains the group variable (in this case, "sex"), and then we tell it which is the "focal" group -- it doesn't really matter, so I've chosen "0" at random, which is female.

```{r}
difMH(gbi10d, "sex", "0")
```

The GBI 10d results suggest no DIF detected. Woohoo!

## RAGA MH Test

Let's try with the RAGA

```{r}
difMH(raga, "sex","0",purify = TRUE)
```

It looks like we might have DIF on 3 items. Let's explore that further using `mirt`.

```{r}
## set the type of invariance we'll test
invariance <- c("slopes", "intercepts")

# Fit the multigroup model with sex as the grouping variable
fit1 <- multipleGroup(
  data = raga[2:17], ## need to cut out the sex column and give only items
  model = 1, # this is a shortcut for a 1-dimensional model
  group = as.factor(raga$sex), # note, group has to be factor or character type
  itemtype = "graded", # graded response model is appropriate for ordinal items
  invariance = invariance,
  verbose = TRUE
)

## Uncomment this line to see the item loadings
# summary(fit1)

## Check for uniform DIF - just in the difficulty parameters
uniform <- DIF(fit1,
               which.par = c('d1','d2','d3','d4'),
               scheme = 'drop'
               # items2test = c("raga_02","raga_03","raga_14")
               )
uniform

nonuniform <- DIF(fit1,
               which.par = c('a1','d1','d2','d3','d4'),
               scheme = 'drop'
               # items2test = c("raga_02","raga_03","raga_14")
               )
nonuniform
## with schema='drop', items with large p-values have DIF.

## fit a model allowing items 2,3, and 14 to vary across groups
fit2 <- multipleGroup(
  data = raga[2:17], ## need to cut out the sex column and give only items
  model = 1, # this is a shortcut for a 1-dimensional model
  group = as.factor(raga$sex), # note, group has to be factor or character type
  itemtype = "graded", # graded response model is appropriate for ordinal items
  ## Below, specify the names of items you want to KEEP INVARIANT
  ## I did this with a shorthand by referencing the column names, but you can just
  ## write out the names of the items in a vector, e.g. c("raga_01","raga_02")
  invariance = colnames(raga[2:17])[c(1,4:13,15,16)],
  verbose = TRUE
)
```

The following plots show the DIF in the item traces

```{r}
itemplot(fit2, item = 2)
itemplot(fit2, item = 3)
itemplot(fit2, item = 14)
```

Note that if we have anchor items, we can specify them in both the MH test and the mirt function above. For MH, we set them with the `anchor.items` argument; with the mirt DIF function, supply `items2test` with the items you think are NOT invariant.
